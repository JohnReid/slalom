{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# slalom tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we illustrate how slalom can be used to identify biological drivers on the mESC cell cycle staged dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load some modules and set some directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/Dev/slalom/venv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import slalom\n",
    "import pdb\n",
    "from slalom import plotFactors, plotRelevance, plotLoadings, saveFA, dumpFA\n",
    "%pylab inline\n",
    "\n",
    "#specify where the hdf5 file is\n",
    "data_dir = '../data/'\n",
    "out_dir = './results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slalom expects an expression file, typically with log transformed gene expression values  as well as a gene set annotation. These data can be provided as single hdf5 file, which can be generated using separate R scripts (in the R folder). Alternatively, the expression matrix and the annotation can be loaded as text files in python. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading raw expression data and gene set annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default we here load the MsigDB annotation, which needs to be downloaded separately from the Broad web page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 182 cells, 6635 genes\n",
      "Annotation: 50 terms\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#Option 1: load a pre-defined hdf5 file\n",
    "#We provide an (optional) hdf file with the required data - this was generated using\n",
    "#the R script write_slalom.R in the R folder\n",
    "if 1:\n",
    "    annoDB = 'MSigDB'\n",
    "    dFile = os.path.join(data_dir,'Buettneretal2015.hdf5')\n",
    "    data = slalom.load_hdf5(dFile, anno=annoDB)\n",
    "    \n",
    "####\n",
    "\n",
    "####\n",
    "#Option 2: load the annotation and the data directly\n",
    "if 0:\n",
    "    #Annotation file\n",
    "    annoFile = os.path.join(data_dir,'h.all.v6.1.symbols.gmt.txt') #MSigDB\n",
    "    annoDB   = 'MSigDB'\n",
    "    if not os.path.exists(annoFile):\n",
    "        raise Exception(\"MSigDB annotation file needs to be downloaded manually\")\n",
    "    #Note: the license of MSigDB does not permit redistribution of the raw annotation files.\n",
    "    #Please register at http://software.broadinstitute.org/gsea/msigdb and download the\n",
    "    #hallmark gene sets and place the file in data folder.\n",
    "\n",
    "    #dataFile: csv file with log expresison values\n",
    "    dataFile = os.path.join(data_dir,'Buettneretal.csv.gz') # note that the first column (row names) contains the cell cycle stage in numeric form\n",
    "    data = slalom.utils.load_txt(dataFile=dataFile,annoFiles=annoFile,annoDBs=annoDB)\n",
    "####\n",
    "\n",
    "###alternatively the data can be loaded from the provided hdf5 file\n",
    "#dFile = 'Buettneretal2015.hdf5'\n",
    "#data = slalom.load_hdf5(dFile, data_dir=data_dir)\n",
    "\n",
    "\n",
    "#print statistics for the loaded dataset\n",
    "print (\"Loaded {:d} cells, {:d} genes\".format(data['Y'].shape[0],data['Y'].shape[1]))\n",
    "print (\"Annotation: {:d} terms\".format(len(data['terms'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the slalom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3be2d29ec68d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#gene_ids: the ids of the genes in Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgene_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#initialize FA instance, here using a Gaussian noise model and fitting 3 dense hidden factors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'genes'"
     ]
    }
   ],
   "source": [
    "#I: indicator matrix that assigns genes to pathways\n",
    "I = data['I'] #if loaded from the hdf file change to I = data['IMSigDB']\n",
    "#Y: log expresison values \n",
    "Y = data['Y']\n",
    "#terms: ther names of the terms\n",
    "terms = data['terms']\n",
    "\n",
    "#gene_ids: the ids of the genes in Y\n",
    "gene_ids = data['genes']\n",
    "\n",
    "#initialize FA instance, here using a Gaussian noise model and fitting 3 dense hidden factors\n",
    "FA = slalom.initFA(Y, terms,I, gene_ids=gene_ids, noise='gauss', nHidden=3, minGenes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "FA.train()\n",
    "\n",
    "#print diagnostics\n",
    "FA.printDiagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the results, including  factor relevance, gene set augmentation and a scatter plot of the two most relevant factors, in this case G2M Checkpoint and P53 Pathway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results\n",
    "\n",
    "fig = plotRelevance(FA)\n",
    "\n",
    "#get factors; analogous getters are implemented for relevance and weights (see docs)\n",
    "X = FA.getX(terms=['G2m checkpoint','P53 pathway'])\n",
    "\n",
    "#scatter plot of the top two factors\n",
    "fig = plotFactors(X=X, lab=data['lab'], terms=['G2m checkpoint','P53 pathway'], isCont=False)\n",
    "\n",
    "\n",
    "#the same plot can be generated by passing the FA object to the plot function\n",
    "#plotFactors(FA=FA,idx1=0,idx2=1, lab = data['lab'], isCont=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize changes for the G2m checkpoint \n",
    "fig = plotLoadings(FA, 'G2m checkpoint', n_genes=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can safe the model results as CSV files or using a .hdf5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.exists(out_dir):\n",
    "#    os.makedirs(out_dir)\n",
    "#out_file_name = os.path.join(out_dir,FA.getName()+'.hdf5')\n",
    "#saveFA(FA, out_name=out_file_name"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
